# ──────────────────────────────────────────────────────────────
# LLM Configuration for Voice Agent System (GPT-4o / GPT-4o-mini)
# Temperature-optimized for reliability and natural tone
# ──────────────────────────────────────────────────────────────

llm_variants:
  # 1) Transcription Quality
  analyze_transcription_quality:
    model: gpt-4o-mini
    temperature: 0.2
    max_tokens: 120
    notes: |
      Quick, deterministic transcript quality evaluation.

  # 2) Answer Extraction
  extract_answer_with_llm:
    model: gpt-4o-mini
    temperature: 0.2
    max_tokens: 200
    notes: |
      Structured extraction; keep responses consistent and valid JSON.

  # 3) Answer Matching
  match_answer_with_llm:
    model: gpt-4o-mini
    temperature: 0.3
    max_tokens: 80
    notes: |
      Fuzzy classification with slight flexibility for phrasing.

  # 4) Intent Detection
  detect_intent_with_llm:
    model: gpt-4o-mini
    temperature: 0.4
    max_tokens: 100
    notes: |
      Intent mapping with moderate flexibility for natural language.

  # 5) Uncertainty Detection
  detect_uncertainty_with_llm:
    model: gpt-4o-mini
    temperature: 0.2
    max_tokens: 40
    notes: |
      Binary certainty check; requires deterministic output.

  # 6) User Data Extraction
  extract_user_data_with_llm:
    model: gpt-4o-mini
    temperature: 0.3
    max_tokens: 250
    notes: |
      Extracts user data fields; allows slight variation to handle paraphrasing.

  # 7) Conversational Response
  generate_conversational_response:
    model: gpt-4o-mini
    temperature: 0.6
    max_tokens: 300
    notes: |
      Produces warm, natural replies for voice tone realism.

  # 8) Orchestrator Decision
  make_orchestrator_decision:
    model: gpt-4o
    temperature: 0.2
    max_tokens: 1000
    response_format:
      type: json_object
    notes: |
      High-stakes decision routing; must output strict JSON.
      Low temperature ensures consistency and validity.
